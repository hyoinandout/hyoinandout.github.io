---
title: "2023 NAVER DEVIEW DAY 2 REVIEW"
---
#SRE #회고 #후기

회사 슬랙에서 2월 8일, 9일 개발자 컨퍼런스인 [NAVER DEVIEW](https://deview.kr/2023) 예약이 열린다고 해서 SRE 세션이 주로 있던 DAY2에 신청을 했고, 어찌저찌(새로운 [토이 프로젝트](https://github.com/hyoinandout/ticket-reservation-app)를 시작하게 되는 계기가 되었다...) 예약완료를 해서 2월 28일날 DAY2에 갔다왔다. 또 어쩌다보니 점심 때 하는 워크샵에 당첨이 되어서 발표 연사자분들과 점심도 먹었다.

첫 번째로 참가한 개발자 컨퍼런스였고 들었던 발표내용이 사내에서 접했던 상황과 많이 유사해서 인상깊었다. 이 글이 \<개발자 컨퍼런스에 처음 가게된 사람\> \<시계열 데이터베이스에 대해 고민중인 사람\> \<NAVER DEVIEW가 어땠는지 궁금한 사람\>에게 도움이 되길 바란다.

![DAY2에서 듣고자 했던 세션](https://user-images.githubusercontent.com/68385607/222951256-a0f67e74-dcc9-4fa7-af67-7a50c64430fb.png)*DAY2 MY SCHEDULE*

### -11:00/ REGISTER & BOOTH
![AF044A97-F75F-4052-9BCA-089C3D0932D0_1_105_c](https://user-images.githubusercontent.com/68385607/222949248-196c7cd1-2d60-40df-a3a8-716caf6634a9.jpeg)*코엑스 입장. 이미 많은 사람들이 와있었다*


참가자 등록은 9시-10시에, 첫 세션은 10시부터 시작이었는데, 버스 자리가 안나와 연거푸 놓치는 바람에 10시 30분 쯤 코엑스에 도착하였다. 위의 MY SCHEDULE에서 볼 수 있듯이 첫 세션 때 들어야겠다! 하는 세션은 없었어서 크게 지장은 없었지만, 모두가 세션을 들으러 발표장으로 들어가서 부스를 빠르게 돌 수 있을 것이라는 예상은 빗나갔다. 참가등록을 한 뒤에 줄이 없는 한 두개의 부스만 돌고 회사 동료분들을 만난 뒤 본격적으로 11:00부터 열리는 ML/AI 개발자를 위한 단계별 Python 최적화 가이드라인 세션을 듣기 위해 트랙으로 들어갔다.

✏️  나중에 알게 됐지만, 이 때가 부스 줄이 없는 편이었다.😅

### 11:00-11:45/ ML/AI 개발자를 위한 단계별 Python 최적화 가이드라인
![DC1C23F3-21C1-443E-9612-47DA9C3016B5_1_105_c](https://user-images.githubusercontent.com/68385607/222949252-ca16198a-a57b-4038-a9d8-b4aca3ba257e.jpeg)*발표장에 들어가자 많은 사람들이 앉아있었다*


본격적으로 발표장에 들어가서 세션을 들었다. 많은 분들이 노트북을 펴고 발표자료를 보고 있었다. 나는 강연을 들을 때 필기를 하기 때문에, 개인 아이패드(필기용)를 가져와서 GoodNote에 필기를 했지만 주변 사람들이 노트북을 펴고 발표자료를 보는 것을 보면서 미리 발표자료를 다운받을 수 있다는 사실을 깨달았다.

✏️  미리 발표자료를 다운받을 수 있다는 사실을 알았다면 발표자료에 필기함으로써 좀 더 효율적으로 필기할 수 있었을 것 같다.

![Untitled Notebook (1)-2](https://user-images.githubusercontent.com/68385607/222956736-fb4241ac-4474-4d7a-a464-39678b5d959d.jpg)*슬라이드를 미리 준비했다면 좀 더 효율적으로 필기할 수 있지 않았을까...*

발표내용은 세션 제목 그대로 ML/AI 개발자를 위한 단계별 Python 최적화 가이드라인이었고, 총 4단계의 가이드라인이 있었다. AI/ML개발자로서 GPU뿐만 아니라 CPU를 최적화해야하는 일이 있는데, 그 때
1. line profiler를 활용해서 코드의 병목지점 확인
2. NumPy나 OpenCV와 같은 python package 더 잘 쓰기(예를 든다면 비트연산자 도입)
3. Cython이나 Numba 사용: pure한 python 코드가 많을 때 유용
4. Python/C API를 사용해서 병목지점 해결하기 (C/C++ 레벨로 내려가서 병렬처리를 한다던지)

와 같은 가이드라인으로 파이썬 코드를 최적화한다면 도움이 된다는 내용이었다.

✏️ AI/ML 개발자는 아니였기 때문에 이런게 있구나~하며 넘어갔던 것 같다.

가이드라인에 대한 설명이 끝나며 발표가 끝난 뒤 네이버 오픈톡을 통한 실시간 Q&A 시간까지 듣고 발표장을 나갔다.

### 12:00-12:45/ LiveOps: 네이버앱의 실시간 운영과 크래시 핸들링 솔루션
![Deview-3](https://user-images.githubusercontent.com/68385607/224541340-21fdfbeb-2d24-4316-bcde-372685c04424.jpg)

모바일 플랫폼 운영의 한계로 인한 문제점들을 네이버는 어떻게 해결했는지에 대한 세션이었다. SRE 토픽 키워드에 이 세션이 들어가 있어 들었었지만 세션 내용은 DevOps 키워드에 조금 더 가깝다고 생각했다. 그 이유는 SRE 철학보다는 클라이언트를 개발하면서 생기는 운영상의 이슈에 대해 대응한 내용이 중점이었기 때문이다.

SRE 토픽과는 조금 멀 뿐 더러 클라이언트 개발과는 무관한 분야에서 일하고 있기 때문에 주의깊게 듣진 않았었지만, 예전에 토이프로젝트로 식단표 앱을 개발할 때 고민했던 내용들과 연관이 있었다. 모바일 어플리케이션 같은 경우 일반적인 웹 어플리케이션 배포 프로세스와 다르기(심사를 맡아야하는, 등) 때문에 장애가 발생할 경우 대처 방식이 일반적인 웹 어플리케이션과 다를 수 밖에 없다. 이것을 해결하기 위해 firebase의 remote config 같은 기능과 유사한 네이버만의 (웹 앱 장애 대응과 비슷한 실시간)해결 사례를 공유하는 세션이었고, 이것은 아쉽게도 오픈소스로는 공개될 계획이 없다고 한다. 

✏️ LiveOps라는 새로운 키워드를 알게 되었다!

그렇게 세션이 끝나고 점심시간이 되었다.

### 13:00-13:45/ \[DAY 2\] DEVIEW 2023 Extended - Meet the Speakers!
![57B5AECB-5B68-4116-A54E-8898D9E97802_1_105_c](https://user-images.githubusercontent.com/68385607/222949254-72453635-0a3f-47e6-af80-cc9a8053099e.jpeg)*코엑스 2층에 따로 장소가 마련되어 있었다*
![EB5480AC-03C9-480F-8666-7BCF6A7F7697_1_105_c](https://user-images.githubusercontent.com/68385607/222949255-756568ca-6795-4e83-b060-4a5431a77190.jpeg)
![CBA411A8-C24C-4CEE-9ED7-B9E665141084_1_105_c](https://user-images.githubusercontent.com/68385607/222949257-25ad592c-26da-4006-9643-6188db9f5b43.jpeg)*공짜 밥은 언제나 맛있다*

점심시간에는 사전 신청했던 워크샵에 참가했다. 교류의 원활함을 위한 명찰과 점심-샌드위치를 받고 자리에 앉아있다가 연사님들이 들어오시면서 워크샵이 시작됐다. 연사와 참여자가 만나서 기술 이야기를 나누며 교류하는 것이 이 워크샵의 취지였는데, 발표자 분들께서 점심시간 끝나고 바로 발표를 하셔서 교류시간이 많진 않았다. 그래도 많이 긴장되셨을텐데 기존 사전질문들에 대해서 정성스럽게 답변을 해주셔서 많은 도움이 되었다. 

기억에 남는 사전질문/답변으로는

- 데이터 처리시 고려 사항은?
	- 데이터 형태와 접근법.
- 장애관제시 인공지능 사용하는가?
	- X
	- 굳이 말하자면 linear regression 사용
	- 안됐던 이유: 충분한 양의 장애 데이터 부재 + 과거 지표 를 사용할수있을까?
	- 결국 휴리스틱을 통한 룰베이스로
- 파편화된 구조를 잘 다루는 법?(분산 시스템)
	- 분산 시스템 표준화(categorize)
- SRE 힘이 강한 회사와 개발력이 강한 회사
- SRE 4가지 골든 시그널은?
	- 도메인 특화적이다.
		- SLO - 구글 클라우드 특성상.
		- 네이버 검색: 장애가 '전무'해야함 -> SLO 안됨, 지표는 계속 바뀌는중
	- 규칙이 정해진 건 아님
- 장애 대응 비율
	- 많지는 않고 전원 모니터링
	- 전사부서 따로 있음
	- 서로 지속적으로 소통
- 오픈소스
	- 빅테크에서 파생
	- 비용절감의 측면
	- 여유가 있을때 도입한 것
	- 희생이 필요함
	- 관심: 오픈텔레메트리

이렇게 좋은 내용들에 대해서 말씀해주셨지만, 나중에 발표를 듣고 이 자리에 참석했다면 더욱 좋지 않았을까... 하는 아쉬움이 들었다. 그 이유는 다음 세션에서 확인할 수 있다.

### ==14:00-14:45/ VictoriaMetrics: 시계열 데이터 대혼돈의 메타버스==

이 세션의 발표 내용이 현재 사내에서 우리팀이 처한 상황과 완전히 똑같다는 점(사용하는 데이터베이스 제외)에서 바로 직전의 워크샵에서 더 이야기를 나누지 못한 아쉬움을 느꼈었다. 정리해서 나누고 싶은 내용이 많지만, 후기글이 길어질 것 같아서 따로 시계열 데이터베이스 특집으로 글을 쓰기로 하고 우선 발표내용을 필기한 내용들이 있는 글을 첨부한다. 후에 링크된 글은 발표내용을 포함해서 시계열 데이터베이스에 대한 글이 될 것이다. [[시계열 데이터베이스]]

발표내용을 간단하게 요약하자면, 네이버 검색 서비스에 들어오는 방대한 트래픽에 대하여 장애를 '절대 내지 않기 위해', 제목의 멀티버스: VictoriaMetrics 인스턴스를 여러개로 나누고 - 그 인스턴스를 클러스터화하고 - 그 클러스터를 또 여러개로 나누어서 HA(고가용성, High-Availability) 대응을 했다는 것이다.

또한 다른 세션을 들으신 팀원으로부터 나중에 알게 된 사실인데 AI플랫폼 쪽에서도 Prometheus를 사용하다가 VictoriaMetrics로 넘어갔다고 한다. 이를 토대로 보면 네이버측에서는 시계열 데이터베이스로 [VictoriaMetrics](https://github.com/VictoriaMetrics/VictoriaMetrics)를 밀고 있는 듯 하다.

우리도 저런 시계열 데이터를 다루지만 RDB에 저장하고 있는데 트래픽이 훨씬 적음에도 불구하고 사용하는 리소스양 측면에서는 별 장점을 못 느끼지 못했다. 하지만 종사하는 도메인 특성상 데이터베이스 교체는 불가능하므로 아마 데이터 모델링을 사용자 수요에 맞게 다시 하지 않을까 생각한다.(스키마를 바꿀 것이 유력하다.) 워크샵 사전 질문에서의, **데이터 처리시 고려사항**이 정말 중요하다는 것을 다시금 느낄 수 있었다.

✏️ 데이터 처리 시 데이터 형태와 접근법을 제 1순위로 고려하자

세션이 끝나고 같이 세션을 들었던 팀원분과 함께 발표자분께 가서 질문을 하고, 밖에 나와서 휴식을 취했다.

### 15:00-15:45/ 휴식

듣고자 하는 세션이 없었고, 직전 세션 때 배운게 너무 많아 팀원분들께 공유하고 쉬기 위해 휴식을 취하였다. 휴식을 취하다가 다 못돌았던 부스를 돌았는데, 몇몇 부스는 끝난 상태여서 굳즈를 예상만큼 받지는 못하였다. 그럼에도 불구하고 다른 부스들에 줄을 서느라 부스를 다 돌지 못했었다. 결국 1개 부스를 못 돈 채 다시 세션을 듣기 위해 발표장으로 들어갔다.

### 16:00-16:45/ 싸늘하다, 메신저에 경보가 날아와 꽂힌다 - 네이버 검색 SRE 시스템 개선기

14시 세션과 마찬가지로 네이버 검색 SRE팀의 발표였다. 14시 세션이 시계열 데이터베이스에 관한 것이었다면 이번 세션은 그 시계열 데이터베이스와 관련된 모니터링 스택에 관련한 것이었다. 이에 대하여 우리는 Grafana와 자체 개발 API를 사용하고 있지만, 여기서는 자체 개발 모니터링 툴와 자체 개발 API를 사용하고 있다는 점에서 비교하면서 들었던 것 같다.

![Deview-17](https://user-images.githubusercontent.com/68385607/224546758-1bef44c1-68f9-4874-b383-e0d0a971223a.jpg)

기존 모놀리틱 구조에서 벗어나, 시각화 컴포넌트와 경보 파이프라인을 분리하며 여러 이점을 누렸다(이 점은 Grafana update와 비슷하다). 또한 ETL 파이프라인을 배치 -> 스트림으로 개선하여 좀 더 빠르게 경보가 발송될 수 있도록 하였다.

![Deview-18](https://user-images.githubusercontent.com/68385607/224546754-997c6af6-8ccc-448b-b8b5-417b72b9eb7b.jpg)

새로운 모니터링 시스템에서 발생한 성능 문제를 해결하기 위하여 1. 지표 계산 쿼리들에 대해 WITH 템플릿 적용 2. 선계산 쿼리 등 여러 노력을 함을 알 수 있었다. 사실 이러한 노력들은 우리가 RDB를 쓰고 있기 때문에 고민하고 있는 바는 아니다.(메타데이터든 뭐든 전부 다 RDB 사용 중이고, 자체 내장 기능이 훌륭하다.) 하지만 이러한 해결법들은 우리의 상황을 '조금 더' 낫게 할 수도 있다는 점에서 좋은 참고가 되었다.

### 귀가

모든 세션이 끝나고, 마저 못 돌았던 1개 부스에서 굳즈를 받고(50분 가량 기다렸다...ㅠㅠ) 귀가하였다. 아래 사진들은 귀가 후 찍은 사진들이다.
![ECFEE3B0-7E0C-4148-834E-9DDDE7C8F630_1_105_c](https://user-images.githubusercontent.com/68385607/222949300-ded986b4-aeca-47fe-974b-01e2e7f344ef.jpeg)*참가 팔찌. 발표장에 들어설 때 이 팔찌를 보여주어야 입장이 된다.*
![A438346F-732D-4967-B2D7-4EABEE6690D9_1_105_c](https://user-images.githubusercontent.com/68385607/222949262-4c09da91-e715-42ad-bd60-a70d5552e690.jpeg)*굳즈를 모두 가방에 챙겨왔는데, 집에 와서 까보니...*
![87E6D057-9713-4480-B2EF-F9B0E1DD26E7_1_105_c](https://user-images.githubusercontent.com/68385607/222949264-c2634c9a-8987-4dbd-b6b9-8599ab69b6c1.jpeg)*많은 수확을 했음을 알 수 있었다.*

아래와 같은 이유들로 이번 2023 DEVIEW는 나에게 특별한 경험이었다.
1. 첫 번째로 참가한 개발자 컨퍼런스
2. 세션 발표내용 ~= 사내에서 고민했던 내용
3. 아기자기 + 유용한 굳즈 수집
4. 신청하지 않았다면, 나중에 유튜브로 시청했을까?
5. 타 회사 사람들과 이야기
6. 예상치 못한 지인 만남
 
다음에도 이러한 컨퍼런스가 있으면 적극적으로 참여신청을 할 것 같다. \<개발자 컨퍼런스에 처음 가게된 사람\> \<시계열 데이터베이스에 대해 고민중인 사람\> \<NAVER DEVIEW가 어땠는지 궁금한 사람\>에게 도움이 되었기를 바라며 글을 마친다.