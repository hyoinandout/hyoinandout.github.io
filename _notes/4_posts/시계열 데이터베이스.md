---
---
[[NAVER DEVIEW DAY 2 REVIEW]]에서 이어지는 글입니다.

시계열 데이터(time series data)란?: 시간 순서대로 나열된 숫자 데이터이다.
ex:
| |60|61|62|
|--|--|--|--|
|A|1|2|3|
|B|4|5|6|

이러한 시계열 데이터의 용량은
*시계열 데이터의 용량 = 데이터 보관 기간 X 시계열 개수* 와 같은 식으로 표현할 수 있고,
아마 이러한 시계열 데이터에 대한 데이터베이스-모니터링 솔루션으로 Prometheus + Grafana를 채택할 것이다.

하지만 네이버 검색 서비스는 15초당 수십억 건의 트래픽이 쏟아지기 때문에 이러한 솔루션이 fully applicable 하지 않다.
![Image 2023-05-21 at 6 57 PM](https://github.com/hyoinandout/hyoinandout.github.io/assets/68385607/ccfe1240-e378-4395-8344-bcc76304d95d)
*참조1[^1] 의 2차 저작물입니다*

수많은 트래픽에 대하여 VictoriaMetric 라는 솔루션을 채택했는데, Prometheus와 똑같은 key-value store 구조의 NoSQL 데이터베이스이지만 Prometheus보다 성능면에서 우수하다.

어떠한 구조가 key-value store 데이터베이스에 쓰이고 있을까?
우선 시계열 데이터의 대략적인 데이터 모델에 대하여 알아보자.

데이터 모델
---
```
http_requests_total{instance="america323", job="search_app", path="/query"} 63 200
http_requests_total{instance="america323", job="search_app", path="/query"} 64 140
```
서버 시작 후 1분 3초에 search_app이라는 job의 /query 라는 path로 200건의 request들이 들어왔다고 해석할 수 있는 데이터이다.

표로 표현하자면
|time series name|63|64|
|--|--|--|
|http_requests_total{instance="america323", job="search_app", path="/query"}|200|140
이다.

이런 식으로 일종의 DB __정규화__ 를 시킬 수 있는데,
time series name 부분은 IndexDB에, 나머지 데이터인 time series datapoints 들은 data storage에 저장할 수 있다.

그러면 IndexDB가 있기 때문에 *http_requests_total{instance="america323", job="search_app", path="/query"}* 에 대하여 일종의 ID를 발급할 수 있다.

이 ID는 다시 분할된 index 값에 대하여 참조 역할(Inverted index) 역할을 한다.
![Image 2023-05-21 at 7 18 PM](https://github.com/hyoinandout/hyoinandout.github.io/assets/68385607/f71959ef-dc98-485f-a6df-a06af0076212)
*참조1[^1] 의 2차 저작물입니다*

이러한 데이터 모델 구조에서 어떠한 알고리즘을 써야 '적은 용량으로' 저장하고 '빠르게' 연산들을 수행할 수 있을까? 즉, 단위 시간마다 수천만의 데이터 유입, 광범위한 데이터를 조회하여 이상을 탐지하기 위해서 어떠한 원리가 적용되어야 할까? (빠른 Read와 Write)

구조
---
이 때 NoSQL에서 사용하는 LSM(Log Structured Merge)Tree가 사용된다.
- Write은 O(1)이며; edit 이 아닌 append 위주 이기 때문이고,
- Read는 O(logn)~O(n)이다; 데이터가 항상 정렬되어있다.

이러한 LSM Tree가 IndexDB와 Data Storage에 적용된다.
![Deview-05](https://user-images.githubusercontent.com/68385607/224543154-3c4445cc-3566-46f4-b52e-dcae5f0b3487.jpg)
*현장에서 필기한 대략적인 LSM Tree 연산 원리*

LSM Tree에 관해서는 [영상](https://youtu.be/i_vmkaR1x-I)에서 너무 잘 설명해주고 있으니 관심이 있다면 도움이 될 것이다.

단점으로는 처음 INSERT를 할 때(처음 index를 생성할 때) 느릴 수가 있다.

연산에 관해서는 LSM Tree를 써서 해결할 수 있는데, 저장용량 관련해서는 데이터를 저장할 때 압축해서 저장을 해야하므로 데이터 모델에 따른 적절한 알고리즘이 필요하다. 이 때 Gorilla Compression이라는 알고리즘을 이용한다.

![](https://user-images.githubusercontent.com/68385607/239736797-54f13238-47f5-47d5-8b53-15269bf5947b.png)
*참조 1[^1]*

사실 시계열은 일정 주기가 있는 값이기 때문에 중복된 값이 있다. 이것을 이용하여 delta of delta encoding으로 timestamp 값을 압축하는 것이다. 16B에서 0.47B 정도의 압축효과가 있다고 한다.

이런 LSM Tree나 Gorilla 알고리즘 이외에도, High Churn Rate 라는 것이  VictoriaMetrics에 있다고 한다. 이것으로 현재 데이터가 시계열 DB를 사용하는게 적절한지 판단할 수 있다.

데이터 속성에 따라 알맞는 데이터베이스 솔루션을 사용하는 것이 정말 중요하다는 것을 느낄 수 있었다.

[^1]:https://deview.kr/data/deview/session/attach/[224]VictoriaMetrics_%EC%8B%9C%EA%B3%84%EC%97%B4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%8C%80%ED%98%BC%EB%8F%88%EC%9D%98_%EB%A9%80%ED%8B%B0%EB%B2%84%EC%8A%A4.pdf