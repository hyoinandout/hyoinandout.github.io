# 운영체제

운영체제란?

A software that acts as an intermediary between a user of a computer and its hardware

EFFICIENCY

KEY POINT

OS structure and services

Process and Threads

Process scheduling 3

Process Synchronization 2

Lock

process가 dual mode switch 어떻게 하는지

mutex로 순서 정하는 가능한 경우의수 고려!!

mutex false : 못 쓰는 것, release 해주라는 것

awake, tick to run ... 국방부 시계

busy waiting이란 while문 뻉뻉

yield 있을때는, schedule ↔ ready라서 계속 얘 실행해야하는지 말아야 하는지 보는거

waiting time 계산은 마지막 실행시간 - 처음 실행 시간 - 그전에 실행만큼

interrupt from device

일단 scheduler 의해 schedule 되면 실행임

Throughput : 처리량

robust : 튼튼한

- Introductions(Overview)
    - What Operating Systems do 5
        - User
            - convenience, ease of use, good performance
        - shared computer
            - keep all users
        - dedicate system
            - frequently use shared resources from servers
        - handheld computers
            - poor resource
    - Computer-System Organization 6
        - Definition
            
            4 components : hardware, operating system, application programs, users
            
            OS = resource allocator , conrol program
            
            kernel : The one program running at all times on the computer, kernel ~= os
            
            ![Untitled](/assets/OS/Untitled.png)
            
        - Interrupt Handling
            
            IO request from components, OS store register and program counter, run interrupt code, restore
            
            ![Untitled](/assets/OS/Untitled%201.png)
            
            1. Polling
            2. Vectored interrupt system
            
            ![Untitled](/assets/OS/Untitled%202.png)
            
        - IO structure
            - Synchronous
                - stops(blocking)
            - Asynchronous
                - device-status table contains entry
                - system call: an interrupt generated by a software
            
            device driver manages IO to handle controllers of each device
            
        - Storage
            - Main memory (largest storage media that the CPU can access directly)
                - RAM(random access memory)
                - volatile
            - Secondary storage (nonvolatile)
                - magnetic disks
                    - track, sector
                - solid-state disks
            
            Speed, cost, volatility
            
            ![Untitled](/assets/OS/Untitled%203.png)
            
            - Caching
                - Hit, Miss
            - DMA (Direct Memory Access Structure)
            
            ![Untitled](/assets/OS/Untitled%204.png)
            
    - Computer-System Architecture 19
        - Multiprocessor Systems = parallel systems, tightly-coupled systems
            - Asymmetric multiprocessing
            
            ![Untitled](/assets/OS/Untitled%205.png)
            
            - Symmetric Multiprocessing(SMP)
            
            ![Untitled](/assets/OS/Untitled%206.png)
            
        - Clustered Systems = loosely coupled systems
            - san
            - services
                - asymmetric clustering
                - symmetric clustering
            - hpc
            - dlm(distributed lock manager)
        
        ![Untitled](/assets/OS/Untitled%207.png)
        
    - Operating-System Architecture 23
        - Multiprogramming
            - organizes jobs so CPU always has one to execute
        - Time sharing(multitasking) - logical extension of multiprogramming
            - process, cpu scheduling
        
        multiprogramming : 여러 프로그램을 돌리게
        
        multitasking : 그 프로그램들을 자유롭게 넘나들게
        
        ram 벅차면 virtual memory가 hard disk  부분에도 있기 때문에 거까지 왔다갔다하느라 느려질것임
        
    - Operating-System Operations 25
        
        asynchronous hardware-driven interrupt → software exception / trap
        
        - Dual-mode operation - mode bit
            - user mode
            - kernel mode
        
        ![Untitled](/assets/OS/Untitled%208.png)
        
    - Process Management 27
        
        Program : passive entity
        
        Process : active entity (program in execution)
        
        ![Untitled](/assets/OS/Untitled%209.png)
        
        single thread : one program counter
        
        multi thread : one program counter per thread
        
        pc = context
        
    - Memory Management 30
        
        Deciding which processes and data to move into and out of memory(swapping)
        
    - Storage Management 31
        - File-system management (access control)
        - mass-storage management
            - speed of computer : hinge on disk subsystem and its algorithm
        
        cache coherency such that all CPUs have the most recent value in their cache memories
        
    - Protection and Security 36
        - Protection : controlling access
        - Security : defense against internal/external attacks
        
        User / group ID : identifier
        
    - Kernel Data structure
        
        BST
        
        Hash function(Virtual Memory)
        
        Bitmap : string of n binary digits representing the status of n items(file system)
        
    - Computing Environments
        - Traditional
            - Portals
            - Network Computers
        - Mobile
            - Apple iOS
            - Google Android
        - Distributed
            - separate, heterogenous
            - Network operating system
        - P2P
            - discovery protocol
            - voice over ip (VoIP)
        - Client - server
        - Virtualization
            - Emulation : slowest
            - Virtualization
                - VMM
        - Cloud Computing
            - AWS EC2
            - Pulbic
            - Private
            - Hybrid
            - SaaS
            - PaaS
            - IaaS
- Operating System Structures
    
    services ? structures ? how ?
    
    - Operating System Services 4
        
        ![Untitled](/assets/OS/Untitled%2010.png)
        
        - helpful to user
            - UI
                - CLI
                - Batch
                - GUI
            - Program execution
            - IO operations
            - File-system manipulation
            - Communications
                - shared memory
                - message passing
            - Error detection
        - efficient operation of the system via resource sharing
            - resource allocation
            - accounting
            - protection & security
    - User Operating System Interface 8
        - cli
            - shells
        - gui
            - desktop
            - icons
    - System Calls 12
        
        provided by the OS
        
        accessed by Application Programming Interface(API)
        
        number is associated with each system call : System-call interface(ex int 21h)
        
        ![Untitled](/assets/OS/Untitled%2011.png)
        
        how to pass parameter in system call?
        
        - stored in registers
        - stored in a block or a table in a memory, and address of the block is passed
        - pushed onto stack and popped off
        
        Block and stack methods do not limit the number or length of parameters being passed
        
        ![Untitled](/assets/OS/Untitled%2012.png)
        
    - Type of System Calls 19
        - Process control
            - debugger, locks
        - file management
        - device management
        - information maintenance
        - communications
            - message passing model
            - shared memory model
        - protection
    - System Programs 27
        
        ≠ system call, (some are indirect, but others are more complex)
        
        - File management
        - Status information
            - registry : used to store and retrieve configuration information
        - File modification
        - Programming-language support
        - Program loading and execution
        - Communication
        - Background services (user context)
            - windows :services , unix : daemons
        - Application programs
    - Operating System Design and Implementation 31
        - Policy : what ?
        - Mechanism : How ?
        
        timer ; ensuring cpu protection :mechanism, how long : policy
        
        High level language - port other hardware easy, but slow
        
        emulation
        
    - Operating System Structure 34
        
        OS is designed by partitioning the task into small components, modules ↔ monolithic
        
        - Simple structure - MS-DOS
        - More Complex - UNIX
        - Layered - an abstraction
        - Microkernel - Mach
            - MacOS X kernel(Darwin) partly based on Mach
            - between user modules, message passing
                
                ![Untitled](/assets/OS/Untitled%2013.png)
                
        - Modules
            - loadable kernel modules
            
            ![Untitled](/assets/OS/Untitled%2014.png)
            
        
        Now on, Hybrid systems
        
    - Operating System Debugging 46
        
        # 보틀-넥, bottleneck, 병목
        
        *명사*
        
        **경제학**
        
        1. 어떤 상품의 수요가 급증해도 원료·설비·노동력 등이 부족하여 생산이 따라가지 못하는 일.
        - dtrace
            - consumer - probes
    - Operating System Generation 51
        - SYSGEN (system generation) : obtains information concerning the specific configuration of the hardware system
    - System Boot 52
        - When power → execution starts at a fixed memory location
        - OS must be made available to hardware so hardware can start it
            - small piece of code - bootstrap loader, stored in ROM or EEPROM, locates the kernel
            - loader → main memory , starts
        - Common bootstrap loader, selection of kernel
        - kernel load and system runs
- Process
    
    process ? features ? ipc ? communication?
    
    - Process Concept 3
        
        OS executes batch system - jobs / time-shared systems - user prgms or tasks
        
        job = process
        
        - Process : a program in execution → process execution must progress in sequential program - exe file, passive / process - active
            - text section
            - program counter, processor registers
            - stack
            - data section
            - heap
        - State
            
            ![Untitled](/assets/OS/Untitled%2015.png)
            
        - Process Control Block (PCB) = task control block
            - Information associated with each process
            - program counter - location of instruction to execute next
                
                ![Untitled](/assets/OS/Untitled%2016.png)
                
        - CPU Switch
        
        ![Untitled](/assets/OS/Untitled%2017.png)
        
        - Threads
    - Process Scheduling 11
        
        Maximize CPU use
        
        - Processor schedulers maintains scheduling queues of processes
            - job queue
            - ready queue
            - device queue
            
            ![Untitled](/assets/OS/Untitled%2018.png)
            
            ![Untitled](/assets/OS/Untitled%2019.png)
            
        - Schedulers
            - short-term scheduler (cpu scheduler) : selects which process to execute
            - long-term scheduler (job scheduler) : selects which process to ready
                - control degree of multiprogramming
            - mid-term scheduler
                - remove process from memory, store on disk, bring back in from disk to continue execution : swapping
                
                ![Untitled](/assets/OS/Untitled%2020.png)
                
            
            Processes can be described as
            
            1. IO bound process : IO > computation
            2. CPU bound process : very long CPU bursts
        - context switch
            - When CPU switches to another process, the system must save the state of the old process and load the saved state for the new process
            - Context = PCB
            - overhead; system does no useful work
    - Operations on Processes 18
        - process creation
            - parent - child → tree
            - pid
            - fork(), exec()
        - process termination
            - exit(), abort() - cascading termination
            - wait() - zombie / orphan
        - example ) chrome browser
            - browser - manage UI, disk & network IO
            - renderer : runs in sandbox(a controlled or emulated section of the system)
            - plug-in
    - Interprocess Communication 27
        
        Information sharing, Computation speedup, Modularity, Convenince
        
        ![Untitled](/assets/OS/Untitled%2021.png)
        
        - Shared Memory
            - synchronization
        - Message passing
            - send, recieve
            - establish communication link
                - how to? - physical (shared memory, hardware bus, network), logical (direct / indirect , synchronous / asynchronous, automatic / explicit buffering)
                    - Direct
                    
                    ![Untitled](/assets/OS/Untitled%2022.png)
                    
                    - Indirect
                    
                    ![Untitled](/assets/OS/Untitled%2023.png)
                    
                    synchronization problem - need policy
                    
                    - Blocking ~= synchronous
                    - Non-blocking ~= asynchronous
                    
                    Buffering
                    
                    - Zero capacity (rendezvous(sender / reciever waiting))
                    - Bounded capacity (wait if full)
                    - Unbounded capacity (never wait)
                - link associated > 2?
        - Producer - Consumer problem
            - Unbounded-buffer : places no pratical limit on the size of the buffer
            - bounded - buffer : assumes that there’s a fixed buffer size
                - shared memory solution : can only use BUFFER_SIZE-1 elements
                
                Producer
                
                ![Untitled](/assets/OS/Untitled%2024.png)
                
                Consumer
                
                ![Untitled](/assets/OS/Untitled%2025.png)
                
    - Examples of IPC Systems 44
        - POSIX shared memory
        - Mach message based
        - Windows message passing via local procedure call(LPC)
            
            ![Untitled](/assets/OS/Untitled%2026.png)
            
            - client open handle to the subsystem’s connection port
            - send connection request
            - server create 2 private communication port
                - client-server message port
                - server- client message port
            - use the port to handle sent message or callbacks and listen replies
            - larger message - section object
    - Communication in Client-Server Systems 50
        - Socket
            - defined as endpoint for communication
            - TCP, UDP
        - Remote Procedure Calls : abstracts procedure calls between processes on networked systems
            
            ![Untitled](/assets/OS/Untitled%2027.png)
            
            - stubs : proxy for the actual procedure
            - client-side stub locates the port on the server and marshal(collects) the parameters
            - windows : MIDL
            - External Data Representation(XDR) : Big endian & Small endian
            
            ![Untitled](/assets/OS/Untitled%2028.png)
            
            - provide matchmaker (rendezvous) service to connect client & server
        - Pipes
            
            ![Untitled](/assets/OS/Untitled%2029.png)
            
            - named pipe : without parent-child relationship, can communicate
        - Remote Method Invocation (Java)
- Threads
    
    thread ? APIs ? implicit ? multi ? support ?
    
    - Overview 4
        - responsiveness
        - resource sharing
        - economy
        - scalability
        
        ![Untitled](/assets/OS/Untitled%2030.png)
        
    - Multicore Programming 8
        - Multicore or multiprocessor systems putting pressure
            - dividing activities
            - balance
            - data splitting
            - data dependency
            - testing & debugging
        - Parallelism for multiple cores
            - Data parallelism - distribute subset of the same data
            - Task parallelism - distribute threads
        - User thread - without kernel support
        - Kernel thread - supported by OS
    - Multithreading Models 12
        - Many to One
            
            Thread is managed by the thread library in user space
            
            If blocking system call → entire process blocks
            
            ![Untitled](/assets/OS/Untitled%2031.png)
            
        - One to One
            
            More concurrency
            
            More overhead
            
            ![Untitled](/assets/OS/Untitled%2032.png)
            
        - Many to Many
            
            ![Untitled](/assets/OS/Untitled%2033.png)
            
        - Two level
            
            ![Untitled](/assets/OS/Untitled%2034.png)
            
    - Thread Libraries 17
        
        provides APIs to a programmer for creating and managing threads
        
        - Implementation
            - user space
            - kernel level
        - Main thread libraries
            - POSIX pthread - specification
            - Win32 threads
            - Java threads
    - Implicit Threading 23
        
        Creation and management of threads done by compliers and run-time libraries
        
        - Thread Pools
        - OpenMP
            - Set of compiler directives
            - Identifies parallel regions
            
            ![Untitled](/assets/OS/Untitled%2035.png)
            
        - Grand Central Dispatch
            - serial queue(Each process has its own serial queue) aka main queue, FIFO
            - concurrent queue : priorities
    - Threading Issues 28
        - semantics of fork() and exec() system calls
            
            ![Untitled](/assets/OS/Untitled%2036.png)
            
        - Signal handling - synchronous & asynchronous
            - Signal : used in UNIX systems to norify a process that a particular event has occurred
            - signal handler
                - signal is generated by particular events
                - signal is delivered to a process
                - signal is handled by one of two signal handlers : default and user-defined
            - default handler → user defined signal handler can override
            - where should a signal be delivered for multi-threaded process?
                - UNIX function : specify process / thread to particular signal to be delivered
        - Thread cancellation of target thread
            - asynchronous : terminate target thread immediately
            - deferred : allows the target thread to periodically check if it should be cancelled
        - Thread-local storage(TLS)
            - when you do not have ctl over the thread creation process (i.e thread pool)
            - ~= static data (unique to each thread)
            
            ![Untitled](/assets/OS/Untitled%2037.png)
            
        - Scheduler activations
            - 1:1
            
            ![Untitled](/assets/OS/Untitled%2038.png)
            
            - M:1
                
                ![Untitled](/assets/OS/Untitled%2039.png)
                
            
            above models not require additional notification(mapping 생각해봐)
            
            - M:M
                
                ![Untitled](/assets/OS/Untitled%2040.png)
                
                - LWP : light weight process : maintain the appropriate number of kernel threads allocated to the application
                - user library sess LWP as virtual processor
                
                Scheduler activation scheme enables upcall procedure (when application thread block) to communicate between the kernel and the upcall handler (user side scheduler) in the thread library
                
                ![Untitled](/assets/OS/Untitled%2041.png)
                
                ![Untitled](/assets/OS/Untitled%2042.png)
                
    - Operating System Examples 38
        - Windows Threads
            - register set, stacks, private storage area : context of the thread
            - ethread, kthread, teb
        - Linux Threads
            - tasks, rather than process or thread
- CPU Scheduling
    
    algorithms ? criteria ?
    
    - Basic Concepts 7
        
        Maximum CPU utilization obtained with multiprogramming
        
        - CPU-IO burst cycle: Process execution consists of
        cycle of CPU execution and IO wait
        - CPU burst followed by IO burst, CPU burst distribution is main concern
        
        ![Untitled](/assets/OS/Untitled%2043.png)
        
        ![Untitled](/assets/OS/Untitled%2044.png)
        
        Short-term scheduler selects one process among the processes in ready queue, and allocates a CPU to it
        
        Nonpreemptive
        
        1. running → waiting(voluntary release)
        2. runnig → ready
        3. waiting → ready
        4. terminates (voluntary release)
        
        Others are preemptive  so should consider:
        
        - access to shared data
        - preemption while in kernel mode
        - interrupts occurring during crucial OS activites
        
        Dispatcher module gives control of the CPU to the process selected by short-term schdle
        
        → switching context, switching to user mode, jumping to proper location in usr progrm
        
        Dispatch latency : time it takes for the dispatcher to stop one process and start another running
        
    - Scheduling Criteria 11
        - Maximize
            - CPU utilization
            - throughput
        - Minimize
            - Turnaround time : amount of time to execute particular process
            - Waiting time
            - Response time : amount of time it takes from the submission of a request until the first response is produced, not output (for time sharing environment)
    - Scheduling Algorithms
        - Waiting time optimization
            - First - Come, First - Served (FCFS) scheduling
                
                ![Untitled](/assets/OS/Untitled%2045.png)
                
                - convoy effect: long → short : slow
            - Shortest-Job-First(SJF) scheduling
                
                ![Untitled](/assets/OS/Untitled%2046.png)
                
                - Associate with the length of next CPU burst in each process
                How to know next CPU request length? → estimate, and pick next-shortest
                : exponential averaging
                    
                    ![Untitled](/assets/OS/Untitled%2047.png)
                    
                - preemptive SJF : shortest-remaining-time-first
                
                ![Untitled](/assets/OS/Untitled%2048.png)
                
                ![Untitled](/assets/OS/Untitled%2049.png)
                
            - Priority scheduling
                
                ![Untitled](/assets/OS/Untitled%2050.png)
                
                smallest int = higher priority
                
                starvation problem : low priority never execute
                
                solution : aging : as time flow, priority of process increase
                
            - Round Robin(RR)
                
                Each process gets a small unit of CPU time(time quantum or time slice q)
                : if time quantum expires, the proces is preempted → ready queue
                
                Timer generates interrupts every quantum to schedule next process
                
                q large → FIFO, q small → too much context switch
                
                ![Untitled](/assets/OS/Untitled%2051.png)
                
                higher average turnaround, but better response(time quantum=4, RR)
                
                ![Untitled](/assets/OS/Untitled%2052.png)
                
                Turnaround time varies with the time quantum
                
            - Multilevel queue
                
                Process permanently assigned to one queue
                
                - foreground(interactive)(RR for better response)
                - background(batch)(FCFS)
                - Scheduling must be done between the queues
                    - Fixed priority scheduling - starvation
                    - Time slice (80% foreground RR, 20% background FCFS)
                    
                    ![Untitled](/assets/OS/Untitled%2053.png)
                    
                    Multilevel feedback queue
                    
                    Q0 → Q1 → Q2 (if not completed while in each queue)
                    
                    ![Untitled](/assets/OS/Untitled%2054.png)
                    
    - Thread Scheduling 30
        
        kernel-level threads are scheduled(user-level thread are mapped indirect or LWP)
        
        - Process-contention scope(PCS): n-1 n-m
            - user level threads ↔ LWP by thread library
            - competition for the CPU (between same process)
            - priority by prgmer
        - System-contention scope(SCS):
            - kernel-thread scheduled into physical CPU
            - competition among all threads
            - 1-1 only SCS
    - Multiple-Processor Scheduling 34
        - Asymmetric multiprocessing
            - only one processor access system data structure
        - Symmetric multiprocessing
            - currently, most common
            - need to keep all CPUs loaded for efficiency : load balancing
                - evenly distributed
                - push migration : push task from overloaded CPU to others
                - pull migration : idle processor pulls waiting task from busy processor
        - Processor affinity(친밀감)
            - soft, hard affinity, variation
    - Real-Time CPU Scheduling 40
        - soft : no guarantee as to when critical real-time process will be scheduled
        - hard : task must be serviced by its deadline
        
        Two types of latencies affect performance:
        
        1. interrupt latency : time interrupt ~ routine
        2. dispatch latency : take current process off CPU, switch to another
        
        (interrupt > dispatch)
        
        ![Untitled](/assets/OS/Untitled%2055.png)
        
        ![Untitled](/assets/OS/Untitled%2056.png)
        
        - priority based scheduling
            
            rate monotonic scheduling
            
            Periodic processes require CPU at constant inervals
            
            ![Untitled](/assets/OS/Untitled%2057.png)
            
            A priority is assigned based on the inverse of its period
            
            ![Untitled](/assets/OS/Untitled%2058.png)
            
            Missed Deadline
            
            ![Untitled](/assets/OS/Untitled%2059.png)
            
            → EDF(Earliset Deadline First scheduling)
            
            ![Untitled](/assets/OS/Untitled%2060.png)
            
            Proportional Share scheduling
            
    - Operating Systems Examples 50
        - linux
            - 0-99 real, 100-140 nice ~2.5
            - 2.63~ Completely Fair Scheduler, -20~19, based on vruntime, lowest
        - windows
            - dispatcher
            - UMS(user-mode scheduling)
        - solaris
            - higher-higher
    - Algorithm Evaluation 63
        
        Deterministic modeling - type of analytic evaluation
        
        ![Untitled](/assets/OS/Untitled%2061.png)
        
        ![Untitled](/assets/OS/Untitled%2062.png)
        
        queueing models - little’s formula : n=lambda * W → limited
        
        simulation
        
- Process Synchronization
    
    synchronization ? critical section ? problems ? solutions ?
    
    - Background 4
        
        concurrent access to shared data may result in data inconsistency
        
        producer - consumer problem(while문 주목)
        
        ![Untitled](/assets/OS/Untitled%2063.png)
        
        counter ++ or counter — atomic? → critical section problem
        
    - The Critical-Section Problem 7
        
        Each process has critical section segment of code
        
        1. ask permission to enter critical section in entry section
        2. may follow critical section with exit section
        3. remainder section
        
        ![Untitled](/assets/OS/Untitled%2064.png)
        
        ![Untitled](/assets/OS/Untitled%2065.png)
        
        solution - three requirements
        
        1. Mutual exclusion
        2. Progress
        3. Bounded waiting
        
        한 프로세스가 자신의 임계 구역에 진입하고자 요청을 한 후부터 이 요청이 허용될 때까지 다른 프로세스가 그들의 임계 구역에 진입할 수 있는 회수가 제한되어야한다. 그렇게 해서 이 프로세스가 cs 진입 가능하게.
        
        출처:
        
        [https://dev-ahn.tistory.com/18](https://dev-ahn.tistory.com/18)
        
        [Developer Ahn]
        
        ![Untitled](/assets/OS/Untitled%2066.png)
        
        Two approaches exist depending on the kernel policy
        
        1. preemptive kernel ✔️
        2. nonpreemptive kernel
    - Peterson’s Solution 12
        
        atomic : load & store
        
        two process share 2 variable : int turn, boolean flag
        
        turn : whose turn?
        
        flag : ready to enter
        
        ![Untitled](/assets/OS/Untitled%2067.png)
        
        1. mutex O
        2. progress O
        3. bounded waiting O
    - Synchronization Hardware 14
        
        support for implementing cs code
        
        idea of locking - protecting critical regions via locks
        
        ![Untitled](/assets/OS/Untitled%2068.png)
        
        atomic = non-interruptible
        
        - test-and-set
            
            ![Untitled](/assets/OS/Untitled%2069.png)
            
            ![Untitled](/assets/OS/Untitled%2070.png)
            
            bounded waiting X
            
            개선
            
            ![Untitled](/assets/OS/Untitled%2071.png)
            
        - compare-and-swap
            
            ![Untitled](/assets/OS/Untitled%2072.png)
            
            ![Untitled](/assets/OS/Untitled%2073.png)
            
            bounded waiting X
            
    - Mutex Locks 21
        
        above functions are hardware-supported
        
        mutex lock : software tools to solve cs problem
        
        - acquire and then release the lock (bool) ← should be atomic : spinlock(aka busy waiting)
        
        ![Untitled](/assets/OS/Untitled%2074.png)
        
    - Semaphores 23
        
        ![Untitled](/assets/OS/Untitled%2075.png)
        
        - Usage
            - counting semaphore
            - binary semaphore = mutex lock
            
            s1 → s2, sema(synch)=0
            
            ![Untitled](/assets/OS/Untitled%2076.png)
            
        - Implementation
            - spinlock can be no good solution; good at cs rarely occupied
            → how about blocking & wake up?
            
            ![Untitled](/assets/OS/Untitled%2077.png)
            
    
    Deadlock & starvation
    
    - deadlock: the state where 2 ≥ processes waiting indefinitely for an event that can be caused by only one of the waiting process
    - starvation: indefinite blocking
    - priority inversion : when a lower priority process holds a lock needed by higher-priority process
    → priority-inheritance protocol
    
    ![Untitled](/assets/OS/Untitled%2078.png)
    
    - Classic Problems of Synchronization 29
        - Bounded Buffer problem
            
            n buffers, each one item
            
            sema mutex init 1
            
            sema full init 0
            
            sema empty init n
            
            → producer holds empty for acquring an empty buffer and consumer holds full for acquring a filled buffer
            
            one of them then tries to hold a mutex for mutual exclusive access to the buffer struct
            
            - producer
            
            ![Untitled](/assets/OS/Untitled%2079.png)
            
            - consumer
            
            ![Untitled](/assets/OS/Untitled%2080.png)
            
            mutex 순서 바뀌면 문제! → bounded waiting 문제 → interrupt 돼서 produce가 또 produce할수도
            
        - Readers and writers problem
            
            shared data
            
            data set
            
            sema rw_mutex = 1
            
            sema mutex = 1
            
            int read_cnt = 0
            
            writer
            
            ![Untitled](/assets/OS/Untitled%2081.png)
            
            reader
            
            ![Untitled](/assets/OS/Untitled%2082.png)
            
            If a writer is in the critical section and n readers are waiting, then one reader is queued on rw_mutex, and n-1 readers are queued on mutex
            
            variations
            
            1. no reader kept waiting unless writer has permission to use shared obj
            2. once writer ready, write asap
            
            Both leads to startvation
            
            **Problem 1**
            
            . writer가 기다리고 있는 경우, reader들은 다른 reader를 기다리지 않고 읽기 시작해야 한다.
            
            → starvation: writer
            
            **Problem 2**
            
            . writer가 준비가 되어 쓰게되면, reader들이 읽기를 기다리고 있기 때문에 가능한 빨리 써야한다.
            
            → starvation: reader
            
        - Dining-philosophers problem
            
            ![Untitled](/assets/OS/Untitled%2083.png)
            
            bowl of rice - data set
            
            semaphore(chopstick[5]) = 1
            
            ![Untitled](/assets/OS/Untitled%2084.png)
            
            deadlock can happen
            
            solution
            
            ![Untitled](/assets/OS/Untitled%2085.png)
            
            방향 정해줘서 가져가면 되긴 하는데 데드락 문제 있음 → 4명만 앉게 한다면? 젓가락을 critical section에서만 가져갈 수 있게 한다면? 비대칭(홀-홀,짝-짝)?→데드락 해결, starvation 문제있음
            
    
    lock, mutex 사용 어려움 → monitor
    
    - Monitors 40
        
        High level abstraction that provides a convenient and effective mechanism for process synchronization
        
        only one process may be active → ADT(abstract data type) include set of programmer defined operations
        
        ![Untitled](/assets/OS/Untitled%2086.png)
        
        conditional variable
        
        ![Untitled](/assets/OS/Untitled%2087.png)
        
        signal and wait or signal and continue
        
        and some implementations … 
        
    - Synchronization examples 53
        - solaris
        - windows
        - linux
        - pthreads
    - Alternative Approaches 59
        - transactional mem
        - openmp
        - fp
- Deadlocks
    
    When deadlock occurs? how to handle deadlocks?
    
    preventing & avoiding deadlocks
    
    - System Model 4
        - Resource type R_1, R_2, … , R_m : CPU cycles, memory space, I/O devices
        - Each resource type R_i has W_j instances
        - Each process utilizes a resources as : request, use, release
    - Deadlock Characterization 5
        
        Deadlock: a state that each member of a group is waiting for the others to take actions for progress (No further progress can be made)
        
        if four conditions hold simultaneously, Deadlock can arise
        
        1. Mutual exclusion
        2. Hold and wait
        3. No preemption
        4. Circular wait
        - Resource allocation graph
            
            How to detect ? no sequence to progress processes
            
            ![Untitled](/assets/OS/Untitled%2088.png)
            
            P2 P4 P1 P3
            
    - Methods for handling deadlocks 12
        1. never enter
            1. prevention
            2. avoidance
        2. recover
        3. ignore(pretend that deadlock never occur) : most operating system
    - Deadlock Prevention 13
        
        Restrain the ways request can be made
        
        1. Mutual exclusion
            1. read-only: not required; mutex lock
        2. Hold and wait
            1. process request resource → has 0 resources now (starvation can occur)
        3. No preemption
            1. think of priority donation
        4. Circular wait
            1. ordering
    - Deadlock Avoidance 17
        - each process declare the max num of resources
        - algorithm - state
        - state : # of available & allocate resources  + max demands of the processes (request 일 때 아닐 때 문제 구분!!)
            - safe state : exist sequence of all the processes in the systems s.t for each P_j the resources that P_i can still request can be satisfied by currently available resources + resources held by all the P_j with j < i
        
        ![Untitled](/assets/OS/Untitled%2089.png)
        
        single instance → graph(no cycle then request ok) / multiple instances → banker’s algorithm
        
        ![Untitled](/assets/OS/Untitled%2090.png)
        
    - Deadlock Detection 31
        - allow system to enter deadlock state
        - algorithm
        - recovery
        
        single instance : wait - for graph(only processes) → n^2
        
        several instance : m*n^2
        
    - Recovery from Deadlock 39
        - process termination
            - abort all deadlocked processes or until deadlock cycle eliminated
        - resource preemption
            - select victim
            - rollback
            - starvation
- Main memory
    
    how OS organizes memory hardware?
    
    paging, segmentation
    
    intel
    
    - Background 4
        
        entire program should be uploaded in the memory
        
        CPU can access register & main memory
        
        cache between cpu register and main memory
        
        base, limit register → logical address
        
        ![Untitled](/assets/OS/Untitled%2091.png)
        
        address binding of instructions and data to memory address
        
        1. compile time → absolute code
        2. load time → relocatable code
        3. execution time  (needs hardware support)
        
        ![Untitled](/assets/OS/Untitled%2092.png)
        
        logical address == virtual address
        
        ≠ at execution - time
        
        physical address - seen by the memory unit
        
        logical address space : set of all logical addresses
        
        physical address space : set of all physical addresses
        
        MMU(memory management unit): maps virtual ↔ physical
        
        base register - relocation register
        
        usr programs deals with logical addresses; never sees real physical addresses(execution time mapping)
        
        ![Untitled](/assets/OS/Untitled%2093.png)
        
        static linking : system libraries and program codes are combined by the loader into the binary program image
        
        dynamic linking : linking is postponed until the execution time
        
        small piece of code : stub
        
        ![Untitled](/assets/OS/Untitled%2094.png)
        
        process larger than main memory size
        
        1. multiple processes’ space sum > size of main memory→swapping
        2. required space of a single process > size of main memory → pagging
    - Swapping 15
        
        ↔ backing store : fast disk large enough to accomodate copies of all memory images for users
        
        ready queue
        
        ![Untitled](/assets/OS/Untitled%2095.png)
        
    - Contiguous memory allocation 20
        
        main memory  = os + user process(single contiguous section of mem)
        
        relocation registers used to protect user processes
        
        ![Untitled](/assets/OS/Untitled%2096.png)
        
        limited by number of partition : variable partition size, hole
        
        ![Untitled](/assets/OS/Untitled%2097.png)
        
        how to satisfy size n memory from list of free holes?
        
        1. first fit
        2. best fit
        3. worst fit
        
        Fragmentation
        
        - external : sum of hole sizes is larger then requested mem size, but not contigu
        compaction?
        - internal : mem allocated to a process > requested mem
    - Segmentation 27
        
        user view of mem
        
        ![Untitled](/assets/OS/Untitled%2098.png)
        
        ![Untitled](/assets/OS/Untitled%2099.png)
        
        logical address = <segment-number,offset>
        
        segment table = base - limit
        
        memory allocation dynamic → problem
        
        ![Untitled](/assets/OS/Untitled%20100.png)
        
        ![Untitled](/assets/OS/Untitled%20101.png)
        
    - Paging 33
        
        avoid external fragmentation(still hv internal fragementation)
        
        divide physical memory into fixed-size blocks called frames(size is power of 2,512B~16MB)
        
        divide logical memory into blocks of the same size called pages
        
        page table: translate logical to physical
        
        ![Untitled](/assets/OS/Untitled%20102.png)
        
        ![Untitled](/assets/OS/Untitled%20103.png)
        
        ![Untitled](/assets/OS/Untitled%20104.png)
        
        ![Untitled](/assets/OS/Untitled%20105.png)
        
        ![Untitled](/assets/OS/Untitled%20106.png)
        
        page table in main memory → two memory access problem, so use associative memory or translation look-aside buffers(TLBs)
        
        ![Untitled](/assets/OS/Untitled%20107.png)
        
        EAT = (m+e)a + (2m+e)(1-a) = (2-a)m + e
        
        memory protection: valid - invalid bit attached to each entry in the page table
        
        ![Untitled](/assets/OS/Untitled%20108.png)
        
        shared page - shared code
        
        each process keeps a separate copy of the code & data
        
        ![Untitled](/assets/OS/Untitled%20109.png)
        
    - Structure of the Page Table 49
        - hierarchical paging
        
        ![Untitled](/assets/OS/Untitled%20110.png)
        
        ![Untitled](/assets/OS/Untitled%20111.png)
        
        ![Untitled](/assets/OS/Untitled%20112.png)
        
        64bit too much → hash
        
        - hased page table
            - virtual page number is hashed in to page table
            - variation for 64-bit addresses : clustered page table(each entry refers to serveral pages) , useful for sparse address spaces
            
            ![Untitled](/assets/OS/Untitled%20113.png)
            
        - inverted page tables
            - track all physical pages
            - one entry for each real page of memory
            
            ![Untitled](/assets/OS/Untitled%20114.png)
            
    - Example: The Intel 32 and 64-bit Architectures 62
        
        ![Untitled](/assets/OS/Untitled%20115.png)
        
        segmentation & segmentation with paging
        
        segment can be 4GB, 16K segments per process → private, global
        
        ![Untitled](/assets/OS/Untitled%20116.png)
        
        ![Untitled](/assets/OS/Untitled%20117.png)
        
        ![Untitled](/assets/OS/Untitled%20118.png)
        
        PAE(page address extension) → allowing 32 bit apps access more than 4GB of memory space
        
        ![Untitled](/assets/OS/Untitled%20119.png)
        
    - Example: ARM Architecture 69
        
        ![Untitled](/assets/OS/Untitled%20120.png)
        
- Virtual memory
    
    benefits? concept of demand paging, page-replacement algorithms, allocation of page frames
    
    shared memory & memory mapped files
    
    how kernel memory is managed
    
    - Background 4
        
        entire program code is not mandatory at one time
        
        - virtual memory - separation of user logical memory from physical memory
            - only part of the program
            - logical address space > physical address space
            - allow address spaces to be shared by several processes
            - allows for more efficient process creation
            - more prgms running concurrently
            - less IO needed to load or swap
        - virtual address space : logical view of how process is stored in memory
        
        virtual memory = demand paging + demand segmentation
        
        ![Untitled](/assets/OS/Untitled%20121.png)
        
        virtual address space
        
        ![Untitled](/assets/OS/Untitled%20122.png)
        
        ![Untitled](/assets/OS/Untitled%20123.png)
        
    - Demand Paging 10
        
        ![Untitled](/assets/OS/Untitled%20124.png)
        
        lazy swapper : unless page will be needed never swaps
        
        ![Untitled](/assets/OS/Untitled%20125.png)
        
        page fault: if there is a reference to a page that is not loaded into the memory yet, the reference will generate a trap to operating system: page fault
        
        ![Untitled](/assets/OS/Untitled%20126.png)
        
        multiple pages → pain decrease because of locality of reference
        
        - stages in demand paging
            1. Trap to the operating system
            2. Save the user registers and process state
            3. Determine that the interrupt was a page fault
            4. Check that the page reference was legal and determine the location of the page on the disk
            5. Issue a read from the disk to a free frame:
            6. Wait in a queue for this device until the read request is serviced
            7. Wait for the device seek and/or latency time
            8. Begin the transfer of the page to a free frame
            9. While waiting, allocate the CPU to some other user
            10. Receive an interrupt from the disk I/O subsystem (I/O completed)
            11. Save the registers and process state for the other user
            12. Determine that the interrupt was from the disk
            13. Correct the page table and other tables to show page is now in memory
            14. Wait for the CPU to be allocated to this process again
            15. Restore the user registers, process state, and new page table, and then resume the interrupted
            instruction
        
        EAT(Effective acces time) : page fault rate p, (1-p)*(mem access) + p(page fault service time)
        
        page fault service time : service the interrupt, read in the page, restart the page
        
        optimization 
        
        1. swap space io faster
        2. copy entire process img to swap sapce
        3. when freeing frame, discard rather than paging out
    - Copy-on-Write 22
        
        allow both parent & child processes to initially share the same pages in memory
        
        if either process modifies a shared page, then the page copied
        
        ![Untitled](/assets/OS/Untitled%20127.png)
        
        no free frame → page replacemnet : algorithm
        
    - Page Replacement 25
        
        prevent over allocation of memory by modifying page-fault service routine to include page replacement
        
        use modify(dirty) bit to reduce overhead of page transfers - only modified pages are writtten to disk
        
        ![Untitled](/assets/OS/Untitled%20128.png)
        
        ![Untitled](/assets/OS/Untitled%20129.png)
        
        page and frame replacement algorithms
        
        - frame allocation algorithm determines how many frames to allocate each process
        - page replacement algorithm : which frames to replace
            - fifo
                - belady’s anomaly: adding more frames can cause more page faults
            - optimal
                - replace page that will not used for longest period of time
            - lru
                - counter implementation
                    - lfu
                    - mfu
                - stack
                - second chacne algorithm & enhanced second chance algorithm
            - page buffering
            
            lru and opt are cases of stack algorithms(pages in memory for n frames are always in memory with n+1 frames) that don’t suffer from belady’s anomaly
            
    - Allocation of Frames 2
        - fixed allocation
            - equal
            - proportional
        - priority allocation
            - local : own set of allocated frame
            - global : can take frame from another
        
        numa(non uniform memory access)
        
    - Thrashing 7
        1. low cpu utilization
        2. os thinks increase multiprogramming to increase utilization
        3. another process added
        4. some running processes require more frames so steal frames from others
        5. stole process generate frequent page fault
        
        a process is busy swapping pages in and out
        
        ![Untitled](/assets/OS/Untitled%20130.png)
        
        demand paging works : locality model
        
        thrashing occur because sum of size locality > total memory size
        
        → use local or priority replacement algorithm
        
        locality = total demand frames(approximation of locality)
        
        PFF(Page Fault Frequency) more direct than WSS(working set size)
        
        ![Untitled](/assets/OS/Untitled%20131.png)
        
        ![Untitled](/assets/OS/Untitled%20132.png)
        
    - Memory-Mapped Files 17
        
        mapping disk block to a page in memory: file io to be treated as routine memory access
        
        speeds file access
        
        ![Untitled](/assets/OS/Untitled%20133.png)
        
        ![Untitled](/assets/OS/Untitled%20134.png)
        
    - Allocating Kernel memory 22
        
        treated differently from usr mem
        
        often allocated from a free mem pool
        
        kerenel requests memory for structure of varying sizes
        
        minimizing waste due to fragmentation
        
        some needs to be contiguous
        
        device io that directly interact with physical memory
        
        → Buddy system : allocates mem from fixed-size seg consisting of physically contiguous pages, using power-of-2 allocator
        
        disadvantage - fragmentation
        
        ![Untitled](/assets/OS/Untitled%20135.png)
        
        slab allocator : alternate strategy
        
        slab: one or more physically contiguous pages
        
        cache : consists of one or more slabs, single cache for eache unique kernel ds
        
        if slab is full of used obj, next obj allocated from empty slab, if no empty, new slab
        
        (partial → empty → new)
        
        → no fragmentation, fast mem request satisfy
        
        ![Untitled](/assets/OS/Untitled%20136.png)
        
    - Other considerations 29
        
        prepaging
        
        page size
        
        - fragmentation
        - page table size
        - resolution( a small page size → high)
        - io overhead
        - number of page faults
        - locality
        - tlb size & effectiveness
        
        tlb reach : amount of memory accessible from the tlb = tlb size * page size
        
        increase page size → frag / provide multiple page size → must indicate size of page
        
        program structure
        
        io interlock → pinning
        
    - Operating-System Examples 34
        - windows
            - demand paging with clustering
        - solaris
            - maintain list of free pages to assign faulting processes
- File System
    
    explain function, describe interfaces, tradeoff(access,file sharing, locking, directory structures)
    
    protection
    
    - background
        
        ![Untitled](/assets/OS/Untitled%20137.png)
        
    - File Concept 5
        
        file: named collection of related information that is recorded on secondary storage
        
        - data
            - numeric
            - character
            - binary
        - program
        - types
            - text
            - source
            - executable
        - attributes
        - operations
        - open files
            - open file table : track open files
            - file open count: to allow removal of data from open file table
        - open file locking
            - similar to reader -writer lock, shared lock - exclusive lock
            - mandatory or advisory
    - Access Methods 11
        
        ![Untitled](/assets/OS/Untitled%20138.png)
        
        ![Untitled](/assets/OS/Untitled%20139.png)
        
    - Disk and Directory Structure 15
        
        ![Untitled](/assets/OS/Untitled%20140.png)
        
        disk - partitions → raid (Redundant Array of Inexpensive/Independent Disk)
        
        disk or partition can be used raw : without file system or formatted with a file system
        
        entity containing file system = volume
        
        volume also tracks that file system’s info in device directory or volume table of contents
        
        ![Untitled](/assets/OS/Untitled%20141.png)
        
        Directory organization : efficiency, naming, grouping
        
        - single level
            - naming problem
            - grouping problem
        
        ![Untitled](/assets/OS/Untitled%20142.png)
        
        - two level
            
            ![Untitled](/assets/OS/Untitled%20143.png)
            
        - tree structured
        
        ![Untitled](/assets/OS/Untitled%20144.png)
        
        - Acyclic graph directories
            - aliasing
            - dangling pointer
                - keeping backpointers
                - entry hold count solution
        - general graph directory
            - no cycle : allowing only links to file and not to subdirectories
            - every time a new link is added, use cycle detection algorithm
    - File-System Mounting 30
        
        file system must be mounted before it can be accessed
        
        ![Untitled](/assets/OS/Untitled%20145.png)
        
    - File Sharing 31
        
        must be done through a protection scheme
        
        user, group
        
        - remote file system
            - networking to allow file system access between systems
                - distributed file systems, www
            - client-server
                - nfs : protocol
                - cifs - windows protocol
        - failure modes
            - recovery from failure involve state information
            - stateless protocols includes all information
        - consistency semantics
            - how multiple users access a shared file
                - AFS
                - UFS
    - Protection 35
        
        owner, group, public
        
- File System Implementation
    
    local file system & directory structure
    
    remote file system
    
    block allocation, free-block algorithms
    
    - File-System Structure 4
        - File structure
            - logical storage unit
            - collection of related information
        - file system
            - resides on secondary storage(disks)
            - user interface (logical → physical)
        - disk - block, sectors
        - file control block : information about file
        - device driver
        
        ![Untitled](/assets/OS/Untitled%20146.png)
        
        - logical file system manages metadata information(inode in UNIX)
        - file organization module understands files, logical address, physical blocks(translate)
        - basic file system give command to device driver
        - device driver manage IO devices
        
        layering useful but overhead
        
    - File-System Implementation 9
        
        On-disk and in-memory structure, implement functions
        
        - on disk
            - boost control block
                - boot os
            - volume control block
                - volume details
            
            In each file, FCB(file control block)
            
        - in memory
            
            ![Untitled](/assets/OS/Untitled%20147.png)
            
        
        partition : volume containing file system or raw
        
        root partition - contains os, other can hold other os …things
        
        at mount time, file system checked
        
        - VFS(virtual file system) (object-oriented way of implementing file systems)(interface)
            
            ![Untitled](/assets/OS/Untitled%20148.png)
            
    - Directory Implementation 16
        - linear list
        - hash table
    - Allocation Methods 17
        
        allocation method refers to how disk blocks are physically allocated for files
        
        - contiguous
            - best
            
            ![Untitled](/assets/OS/Untitled%20149.png)
            
        - extent based
            - disk block - extent
            - extent is contiguous block of disks
            
            ![Untitled](/assets/OS/Untitled%20150.png)
            
        - linked
            - ends at nil pointer
            - no external fragmentation, no compaction
            
            ![Untitled](/assets/OS/Untitled%20151.png)
            
            FAT(File allocation table variation)
            
            beginning of a volume, table indexed by block numbers
            
            ![Untitled](/assets/OS/Untitled%20152.png)
            
        - indexed
            
            ![Untitled](/assets/OS/Untitled%20153.png)
            
            - linked scheme
            - multilevel scheme
        - performance
            - contiguous is best
            - list not good for random
    - Free-Space Management 27
        
        free space list
        
        - bit vector or bit map
            - easy to get contiguous files
        - linked list
        - grouping
        - counting
        - space maps
    - Efficiency and Performance 32
        - efficiency
            - disk allocation, directory algorithms, types of data, pre allocation, data structures
        - performance
            - buffer cache, synchronous, asynchronous, free-behind & read ahead
            - reads are slower than writes
        - page cache
            - cache pages
            
            ![Untitled](/assets/OS/Untitled%20154.png)
            
            ![Untitled](/assets/OS/Untitled%20155.png)
            
    - Recovery 38
        
        consistency checking data in directory vs data in disk
        
        back up
        
        log structured file system 
        
- Q&A
    
    Deadlock p9 & 10 : why deadlock 
    
    Deadlock p29 : P0 P2도 되지 않나? 순서가 항상 low → high 계속 도는?
    
    Main memory p 20 : operating system high memory 아닌가?
    
    Main memory p 25 : 0.5/(1+0.5)에서 1은 왜 더하는건지?
    
    Main memory p 31 : s,d의 의미
    
    Main memory p 43 : EAT 공식 내가 이해한게 맞는지?
    
    Main memory p 64 : Intel 32칩의 발전 형태?
    
    Virtual memory 1 p 26
    
    Virtual memory 2 p 4 
    
    Virtual memory 2 p 12
    
    Virtual memory 2 p 16 풀어보기
    
    LRU와 FIFO의 차이??
    
    mmap의 장점?
    
    File System Implementation p 11 그림 2개
    
    - 기출 문제
        
        locality size? locality?
        
        backing store → 하드디스크에 있는 것?
        
        safe state & unsafe state?
        
        continuous memory allocation?
        
        if not in page not in backing store in page fault?
        
        5-b pure page demand : optimal : 나중 횟수 같으면 상관 없는지
        
        LRU?
        
        2^10? 10^3?
        
        20년도 1-e-D 내가 생각한게 맞는지
        
        20년도 3번 b 판단법
        
        20년도 6-b
        
        21년도 6-d 블록사이즈 늘리는건 안되나?
        
- Q&A Session
    
    file system p7 : os 따라 mmap 인지 아닌지 달라짐
    
    p8 : file descriptor 내 file pointer
    
    free space management: 시작점 기준으로
    
    need for page replacement : vm에 올라와있다고 가정해서 오버랩 ← 이미 디스크 상에 올라온걸 참조하는 것이 아닌???